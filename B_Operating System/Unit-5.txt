Memory Management & Degree of MultiProgramming :-
 - Method of managing and Efficient utilization of primary memory
 - Memory is large arrays of byte where every byte has some address where some memory occupied by OS when system start
 - Maximum Utilization(Minimum Fragmentation) 
 - Run Larger Program with limited space(Using Virtual memory)
 - If process size is more than size of memory then that process accommodate in main memory which known as overlay

 Formula :- Cpu Time = (1-k^n)  # n means no of process | k - I/O Operation time
 Diagram :- CPU -> Logical Address -> [ MMU [Base Register] ] -> Physical Address

 MMT Types :-
  Contiguous     :- Enitre process store in consecutive location | Fixed Partition, Variable Partition
  Non-contiguous :- Process store in non-consecutive location    | Paging, Segmentation
 


Contiguous Memory Management Techniques :-
 - Provide Contiguous(consecutive) Memory Block for process in RAM

 Fixed / Static Partition :-
  - No. of memory Partition fixed and evey partition allocate only one process 
  - Partition size will be same or may not same
  - Spanning Put entire process in same partition, Not allow to put in different partition
  - If Process size bigger than partition size in memory it generate problem of partition size limit
  - Fixed no. of partition so Not add more processes in RAM above partition size
  - Combination of all available memory in different slots equal to process size or less size(External Fragmentation)
  Ex :- If P1 = 2MB and M1 = 4MB remaining M1 2MB size was wasted which called Internal Fragmentation 

  
 Variable / Dynamic Partition :-   
  - Allocating space for process based on their space requirement(Partition size Same as process size)
  - Main memory not divided into partition initially 
  - No chance for internal Fragmentation
  - No limitation on Degree of programming(No Of Process) and process size 
  - Process complete its execution in RAM it create one hole(4MB) 4MB + 4MB BUT Process size 8MB so Fragmentation
  - Use Compaction to remove fragmentation 
  - Compaction Collect all allocated process one side and remaining space other side
    means stop process or move process from one address to another which take more time
  - Allocation and deallocation little bit complex  


 Process Allocation Policy(How to allocate process in Hole):-
  First-Fit :- 
   - Allocate first partition that big enough for that process            
   - P1=15KB => S1=25KB | S2=35KB store in S1
   - Search from beginning so searching time low and fast 
   - Remaining portion of memory create big holes in memory so internal Fragmentation


  Next-Fit  :- 
   - Same as first fit but start search always from last allocated hole 
   - p2=15KB => S2=28KB | S3=30KB store in S2 Not S1
   - Not need to search from beginning because First-Fit already searched


  Best-Fit  :- 
   - Search entire list and allocate smallest partition that big enough for process so minimal internal fragmentation
   - Problem Create tiny holes which not helpful for other and search entire ram so very Slow
   - p2=15KB => S5=22KB | S8=20KB  Store in S8 Not S2 
                
  
  Worst-Fit :- 
   - Allocate largest hole
   - p2=15KB => S5=22KB | S8=20KB  Store in S5 Not S8
   - Problem Create big holes where other process join but search entire ram so very Slow

   
  Example :- 
   Request from process are 300kb, 25k, 125k, 50k so which will be best for it :-
   R1 = 150KB  | R2 = 350KB  # Hole
    First Fit :- P1 --> R2(50) | P2 --> R1(125)  | P3 --> R1(0)  | P4 -->R2(0)
    Best Fit  :- P1 --> R2(50) | P2 --> R2(25)   | P3 --> R1(25) | P4 Not fit with space because R1(25), R2(25)
    Worst Fit :- P1 --> R2(50) | P2 --> R1(125)  | P3 --> R1(0)  | P4 -->R2(0)


  Example With TimeLine :- BestFit
   Calculate time at which "J7" will be completed _____ :- ANS :- b if ask when enter time it ANS :- 11
   a)17    b)19    c)20    d)37
    
   RNo.        J1  J2   J3   J4   J5   J6    J7   J8
   RSize       2K  14K  3K   6K   6K   10K   7K   20K
   UsageTime   4   10   2    8    4    1     8    6 

   Partition Size :- R1(4K) | R2(8K) | R3(20K) | R4(2K)

   Gannt Chart :- 0    2       4        8       10     11      12          19
                       J3     J1       J4       J2     J6      J5(8+4)     J7

   Solve :- 
    - J1 --> R1(0)() | J2 --> R3(6K) | J3 --> R1(1K) | J4 --> R2(2K)
    - Slot full waiting for release other process 
      J4C --> R2(8K) | J5 --> R2(2K) | J2C --> R3(20K) | J6 --> R3(10K)
    - At time 11 J6 Remove and At 12 J5 Remove but we need to consider 11 time
      J6C --> R3(20K) | J7 --> R3(13K)  
       


Non-Contiguous Memory Management Techniques :-
 - Process divided and place in different location for removing external fragmentation
 - Holes created dynamically so whenever process come in ram Check holes and its size than according size divided 
   process to fit in that location so very time consuming
 - To solve these divide process before enter in ram that called pages
 - Size of Page = Size of Frame(Main memory Partition)

 Paging :-
  - Process Divided in equal size of pages and insert into same size Frames(Physical memory Partition)
  - Frame and page numbers are represent in binary so its always start with 0
  - Every process has its own page table that containing frame number where process page is allocated in memory
  - Page table also store in main memory in form of pages
  - Number of entries in page tables = Number of page in process 
  - Each entry in page tables contains = Frame No. + Extra-bits

  Diagram :-
   Process        Page Table       Physical Memory
               PageNo. Frame No   Frame No
    Pg-1          2       2         0       Pg-N   
    Pg-2          1       1         1       Pg-1                
    Pg-N          N       0         2       Pg-2
                                      

  Mapping :- 
   - Process of Convert Cpu generated logical address into absolute address done by MMU(Memory Management Unit)
   - CPU works on logical address space(LAS) which created by two factor :- Page  number and page  offset(sizeof page)
   - Physical address space (PAS) represent location of bytes in memory  :- Frame number and Frame offset(sizeof frame)


  Formula :- 
    Page Table Size = No. of entries in P.T.  * 1 Entry Size
                    = No. of pages in process * 1 Entry Size(Frame no + Extra bits) 
   
   
  Page Table Entry :-
   - Page table Use MMU to convert logical address into physical address for mapping
   First Field  -> Frame No (Mandatory)
   Second Field -> Valid-1/Invalid-0 | Tells whether page is present or not at that location(Page Fault) 
   Protection(RWX)(Read Write Execute) -> Check Permission on particular file or page  
   Reference(0/1)  -> When swapping page it need to tell either bring that page in past using LRU(least recently used)
   Caching         -> Enable or disable caching 
   Dirty/Modified  -> User change any page data or update data to update data in secondary memory


  Multi-level | 2-Level Paging :-
   - Page table size bigger than main memory frame size divided it into smaller page(Outer page) and stored
     page into outer page


  Inverted Paging :-
   - Instead of keeping all page table of all process there will be only one page table(Global Page Table)
   - Global page table contain --> Frame No | Page No | Process ID 
   - No. of frame in frame table is same no. of page entries
   - Problem is searching time because it use Linear Search 



 Segmentation :-
  - Divide process into segment(Releated Part) then put into memory
  - Each segment has different logical address space of program
  - When process executed corresponding segmentation loaded into non-contiguous memory though every segment loaded 
    into contiguous block of available memory
  - Segment contain program main, utility function, data structure etc..
  - Paging divided process without known user which occurs in different problems(Function Problem C Program)
  - In paging all page size same while in segment size are not same
  - OS maintain Segment map table which used to convert logical address into physical address
  - Segment table contain --> Segment No  :  Segment Size  :  Base address(From where its start)
  Trap :- If cpu demand is higher than actual segment size 

  Diagram :-
     Process      Segment Map Table                       Main Memory
                Segment Number   Size   Memory Address     OS 
    Segment-1         1           400    100              
    Segment-N         N            x     NM                100 
                                                           NM



Virtual Memory :-
 - Provide illusion to execute process if its size larger than physical memory
 - Divided process --> Allow only Required Process Page in main memory
 - Section of hard disk that emulate computer RAM
 - MMU translate virtual addresses into physical addresses
 - Extend use of physical memory by using disk 
 - Memory protection because each virtual address translated to physical addresses 
 - Virtual memory implemented by demand paging or demand segmentation system

 Diagram :- 
  Virtual Address   Physical Address    Secondary Memory
    0     A             0                     D
    4K    B             4K     C              B
    8K    C             8K    
    12k   D             12K     
                        16K    A
 
 

 Demand Paging :-
  - Pages loaded into memory only when CPU wants to access them(lazy sweaper -> Pager)
  - If CPU wants to access page that is not in Memory called Page Fault
  - Trap :- Highest prioriy non-maskable external-hardware interrupt
  - Large virtual memory | Efficient memory usage | No limit on degree of multiprogramming
  Page Replacement :- Process of replaceing one page by another in memory when there is no free frame
  
  Pure Demand Paging :- 
  - Execution of process started with none of its pages in memory
  - Starting is fast and response low
  Access Time :- (1-p) x Memory Access time + p x Page fault service time 

  Diagram :-
    Logical Memory  |  [  | v] Page Table  |  Physical Memory   |   Disk 
                       [  | i]
   - v(Valid)   Page is in memory
   - i(Invalid) Page not Mandatory



Page Replacement Algorithm :- 
 - Used by OS to decides which memory pages to swap out, write to disk when page of memory needs to be allocated
 - Paging happens whenever page fault occurs and free page not be used for allocation
 - Lesser waiting time for page-insert the better is the algorithm
 - PRA look limited information about accessing pages provided by hardware and tries to select pages that should
   be replaced to minimize total number of page misses and balancing it with primary storage cost and processor time
   of algorithm itself

 - Evaluate algorithm by running it on particular string of memory reference and computing number of page fault
 - String of memory reference called reference string and generated by random number generator 
 - For given page size consider only page number not entire address
 Local Page Replacement  - Process control its page fault rate
 Global Page Replacement - Better throughput, Commonly Used

 Diagram :-     
  Number  | |       - Typical Response
  of page |   |
  faults  |     |
          |----------------->
            Number of frames

 First-in-first-out(FIFO) :- 
  - No need to note time, Only Queue Required | Performance not good 
  Belandy's anomly :- Numbers of page fault increases with number of frames allocated

 Optimal Page Replacement Algorithm :-
  - Replace page that not used for longest period of time
  - lowest page fault rate, No Belandy anomaly
  - Used for comparison | Impossible to implement

 Least-Recently Used(LRU) :-
  - Replace least-recently used page | No Belandy anomaly
  - Page table has Minimum 'time of use' value
  - Implemented using counters and stack
  - Logical clock must not overflow
  - Maintain stack of Page number referenced
  - Most system not provide necessary support for LRU but reference bit used for each page table entry
  - Initally, referenced bit - 0 | If referenced, bit-1

 Stack Algorithm :-
  - Doesn't suffer from Belandy algorithm
  - Page in memory for n frames is always subset of pages in memory(N+1) frames
  N frames  : n most recently used pages in memory | N+1 frame 

 Least Frequently used(LFU)  |  Most Frequently used(MFU) :-

 Frame Allocation :-
  - Minimum no. of frames otherwise too many page faults
  - Equal Allocation | Proportional Allocation



Thrashing :-
 - System spending more time in servicing page faults than executing
 - Cpu ask for page but its not available called Page Fault and it check by Page Fault Service Time 
 - When page fault service takes lots of time and entire OS busy in servicing page Fault
 - Page Hit Decreases and page Fault become heavy Due to that CPU utilization decreases suddenly known as Thrashing
 - To remove it either increases main memory size or decreases long-term scheduler speed
 - Scheduler load more processes in memory so due to high pageing CPU Utilization high that go in Thrashing
 - Working Set model used to Avoiding Thrashing
